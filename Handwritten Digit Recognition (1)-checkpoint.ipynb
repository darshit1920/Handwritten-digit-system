{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cce955d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "## Loading - 'MNSIT Data Set'\n",
    "## Containing Training samples = 60,000   , Testing samples = 10,000\n",
    "## Tensorflow already contain MNIST data set which can be loaded using Keras\n",
    "mnist = tf.keras.datasets.mnist  ##this is basically handwritten based on 28x28 sized images of 0 to 9\n",
    "## After loading the MNIST data, divide into train and test datasets\n",
    "##unpacking the dataset into train and test datasets\n",
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
    "##just check the graph, how data looks like\n",
    "import matplotlib.pyplot as plt ## to import images\n",
    "## Checking the values of each pixel\n",
    "## Before normalization\n",
    "## As images are in Gray Level (1 channel ==> 0 to 255), not Colored (RGB)\n",
    "## Normalizing the data | Pre-Processing Step\n",
    "## you might have noticed that, its gray image and all values varies from 0 to 255\n",
    "## in order to normalize it\n",
    "x_train = tf.keras.utils.normalize(x_train,axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test,axis =1)\n",
    "## After Normalization\n",
    "## Resizing image to make it suitable for apply Convolution Operation\n",
    "import numpy as np\n",
    "IMG_SIZE = 28\n",
    "x_trainr=np.array(x_train).reshape(-1,IMG_SIZE,IMG_SIZE,1)    ## increasing one dimension for kernel=filter operation\n",
    "x_testr=np.array(x_test).reshape(-1,IMG_SIZE,IMG_SIZE,1)      ## increasing one dimension for kernel operation\n",
    "## Creating a Deep Neural Network\n",
    "## Training on 60,000 samples of MNIST handwritten dataset\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten,Conv2D,MaxPooling2D\n",
    "## creating a neural network now\n",
    "model= Sequential()\n",
    "## First Convolution Layer 0,1,2,3  (60000,28,28,1)  28-3+1=26x26\n",
    "model.add(Conv2D(64,(3,3),input_shape = x_trainr.shape[1:]))  ## only for first convolution layer to mention input size\n",
    "model.add(Activation(\"relu\"))    ## activation function to make it non -linear, <0,remove,>0\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))     ## MaxPooling single maximum value of 2x2,\n",
    "\n",
    "##2 Convolution layer         26-3+1=24x24\n",
    "model.add(Conv2D(64,(3,3))) \n",
    "model.add(Activation(\"relu\"))    ## activation function\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))    ## MaxPooling\n",
    "\n",
    "## 3 Convolution Layer\n",
    "model.add(Conv2D(64,(3,3)))    ## 24x24\n",
    "model.add(Activation(\"relu\"))    ## activation function\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "## Fully connected layer 1     20x20=400\n",
    "model.add(Flatten())   ## before using fully connected layer, need to be flatten so that 2D to 1D\n",
    "model.add(Dense(64))  ## neural\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "##Fully connected layer 2\n",
    "model.add(Dense(32))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "##Last fully connected layer, output must be equal to number of classes, 10(0-9)\n",
    "model.add(Dense(10))  ## as this dense layer must be equal to 10\n",
    "model.add(Activation('softmax'))  ## activattion function is changed to Softmax (claslsl probabilities)\n",
    "## binary classifiaction, one neuron in Dense Layer, sigmoid\n",
    "model.compile(loss =\"sparse_categorical_crossentropy\",optimizer=\"adam\",metrics=['accuracy'])\n",
    "model.fit(x_trainr,y_train,epochs=5,validation_split=0.3)   ## Training my model\n",
    "##Evaluating on testing data set MNIST\n",
    "test_loss,test_acc = model.evaluate(x_testr,y_test)\n",
    "## predictions =new_model.predict(x_test)   ## there is specialized method for efficiently saving your model, to name all input\n",
    "## therefore, instead of using new model loaded, for now only prediction I am using simple model\n",
    "predictions=model.predict([x_testr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3a08f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "n=input(\"Enter the name of file: \")\n",
    "img=cv.imread(n)\n",
    "plt.imshow(img)\n",
    "gray= cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "resized=cv.resize(gray,(28,28),interpolation= cv.INTER_AREA)\n",
    "newimg= tf.keras.utils.normalize(resized,axis =1)  ## 0 to 1 scaling\n",
    "newimg=np.array(newimg).reshape(-1,IMG_SIZE,IMG_SIZE,1) ## kernel operation of convolution layer\n",
    "predictions =model.predict(newimg)\n",
    "print(\"The digit wriiten is: \",np.argmax(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67387d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd18d28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
